{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-24T18:03:22.896883Z",
          "iopub.status.busy": "2026-02-24T18:03:22.896636Z",
          "iopub.status.idle": "2026-02-24T18:03:23.166287Z",
          "shell.execute_reply": "2026-02-24T18:03:23.165623Z",
          "shell.execute_reply.started": "2026-02-24T18:03:22.896862Z"
        },
        "id": "4o07Q2WK0wBM",
        "outputId": "34f87173-ded6-4298-d196-3d159a052739",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd # data processing, CSV file\n",
        "\n",
        "import os\n",
        "pName = \"\"\n",
        "for dirname, _, filenames in os.walk('./database'):\n",
        "    for filename in filenames:\n",
        "        pName = (os.path.join(dirname, filename))\n",
        "        print(pName)\n",
        "        \n",
        "if pName != \"\":\n",
        "    print('Data source import complete.')\n",
        "else:\n",
        "    print('Data source import failed.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T18:03:23.171305Z",
          "iopub.status.busy": "2026-02-24T18:03:23.171131Z",
          "iopub.status.idle": "2026-02-24T18:03:28.084619Z",
          "shell.execute_reply": "2026-02-24T18:03:28.083874Z",
          "shell.execute_reply.started": "2026-02-24T18:03:23.171287Z"
        },
        "id": "ZeO4rnKz0wBN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(pName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-24T18:03:28.086144Z",
          "iopub.status.busy": "2026-02-24T18:03:28.085978Z",
          "iopub.status.idle": "2026-02-24T18:03:28.102788Z",
          "shell.execute_reply": "2026-02-24T18:03:28.10226Z",
          "shell.execute_reply.started": "2026-02-24T18:03:28.086126Z"
        },
        "id": "3CbSKU8I0wBN",
        "outputId": "b1ea93c4-fc28-4bb3-e57a-05963c0e004b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-24T18:03:28.103548Z",
          "iopub.status.busy": "2026-02-24T18:03:28.103391Z",
          "iopub.status.idle": "2026-02-24T18:03:28.115712Z",
          "shell.execute_reply": "2026-02-24T18:03:28.115183Z",
          "shell.execute_reply.started": "2026-02-24T18:03:28.103531Z"
        },
        "id": "ipcwLiX80wBO",
        "outputId": "3573d9cf-dba6-41a4-efaf-6ca1c6658cda",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df['diseases'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-24T18:03:28.1165Z",
          "iopub.status.busy": "2026-02-24T18:03:28.116324Z",
          "iopub.status.idle": "2026-02-24T18:03:28.129759Z",
          "shell.execute_reply": "2026-02-24T18:03:28.129242Z",
          "shell.execute_reply.started": "2026-02-24T18:03:28.116483Z"
        },
        "id": "DewfJtpA0wBO",
        "outputId": "f7831dac-9b61-4356-c938-0917d284b8e0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df['diseases'].unique()[:200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68FS-ldU0wBO"
      },
      "source": [
        "## Imbalanced value counts\n",
        "\n",
        "_Don't worry - having lesser training data for some diseases is fine. Their probability of occurrence in the real world is negligible. The occurrence probability in this dataset is roughly proportional to the value counts._\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2026-02-24T18:03:28.147697Z",
          "iopub.status.busy": "2026-02-24T18:03:28.147528Z",
          "iopub.status.idle": "2026-02-24T18:03:28.163538Z",
          "shell.execute_reply": "2026-02-24T18:03:28.163038Z",
          "shell.execute_reply.started": "2026-02-24T18:03:28.14768Z"
        },
        "id": "fth8OOGy0wBP",
        "outputId": "e7502a35-8f62-401b-a9b5-30b37afb9169",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.diseases.value_counts().loc[lambda x : x <= 10].reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Now I will split dataset into X and y and train a model using sklearn LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Convert DataFrame to NumPy first\n",
        "X = df.drop(columns=['diseases']).to_numpy()\n",
        "y = le.fit_transform(df['diseases'])\n",
        "\n",
        "# Now convert to tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Dataset + DataLoader\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SymptomClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SymptomClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)  # logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SymptomClassifier(X.shape[1], len(le.classes_)).to(device)\n",
        "print(f\"Using device: {device}\") \n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(20):  # adjust epochs\n",
        "    for batch_X, batch_y in loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prediction function\n",
        "def predict_symptoms(symptoms_vector):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs = torch.tensor(symptoms_vector, dtype=torch.float32).to(device)\n",
        "        outputs = model(inputs)\n",
        "        predicted = torch.argmax(outputs).item()\n",
        "    return le.classes_[predicted]\n",
        "\n",
        "# Example: predict first row\n",
        "print(predict_symptoms(X[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SAVE AND LOAD MODEL\n",
        "\n",
        "torch.save(model.state_dict(), \"torch_symptom_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Define the same architecture you used before\n",
        "class SymptomClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SymptomClassifier, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_dim, 64)\n",
        "        self.fc2 = torch.nn.Linear(64, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)  # logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = SymptomClassifier(X.shape[1], len(le.classes_))\n",
        "model.load_state_dict(torch.load(\"torch_symptom_model.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_top_diseases(symptoms_vector, top_k=3):\n",
        "    listOfSymptomsHeader = df.columns[:-1].tolist()  # all columns except 'diseases'\n",
        "    for i in range(len(symptoms_vector)):\n",
        "        if symptoms_vector[i] == 1:\n",
        "            print(f\"Symptom: {listOfSymptomsHeader[i]} is present.\")\n",
        "    print(\"\\nPredicting top diseases based on symptoms...\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs = torch.tensor(symptoms_vector, dtype=torch.float32).to(device)\n",
        "        outputs = model(inputs)\n",
        "        probs = torch.softmax(outputs, dim=0).cuda(device=device).cpu().numpy()  # move to CPU and convert to NumPy\n",
        "\n",
        "    # Sort probabilities in descending order\n",
        "    sorted_indices = np.argsort(probs)[::-1]\n",
        "    top_indices = sorted_indices[:top_k]\n",
        "\n",
        "    # Build list of (disease, probability)\n",
        "    top_diseases = [(le.classes_[i], probs[i]) for i in top_indices]\n",
        "    return top_diseases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "allResults = []\n",
        "for i in range(100,200):\n",
        "    print(i , \"=\" * 46, i)\n",
        "    sample = X[i]  # row of dataset\n",
        "    top_results = predict_top_diseases(sample, top_k=4)\n",
        "\n",
        "    print(f\"\\nTop probable diseases for sample {i}:\")\n",
        "    \n",
        "    for disease, prob in top_results:\n",
        "        print(f\"{disease}: {prob:.2f}\")\n",
        "    print(\"------------------------x-------------------------\\n\")\n",
        "    allResults.append((i, top_results))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame(allResults, columns=[\"Sample Index\", \"Top Predictions\"])\n",
        "\n",
        "df_results.to_csv(\"top_disease_predictions.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "FirstDoctor-WorkThief",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "tpuV5e8",
      "dataSources": [
        {
          "databundleVersionId": 6527833,
          "datasetId": 3720943,
          "sourceId": 6446106,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30558,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
